---
title: "Beef Topic Modeling MY COPY"
output: html_notebook
---

# Topic Modeling to Inform Survey Questions

```{r, message=FALSE}
library(tidyverse)
library(tm)
library(topicmodels)
library(tidytext)
library(plyr)
library(stringr)
library(ggplot2)

# raw <- c('tyson_scrape', 'cargill_scrape', 'beef_scrape')
# for (i in 1:length(raw)){load(paste0(raw[i],'.Rdata', sep = ""))}
# 
# tyson <- tweets_tyson %>% ldply(function(t) t$getText())
# cargill <- tweets_cargill %>% ldply(function(t) t$getText())
# beef <- tweets_beef %>% ldply(function(t) t$getText())
# all_tweets <- rbind(tyson, cargill, beef)

load("all_tweets.Rdata")
```
Load Libraries & Previously-Scraped Raw Tweets, Extract Text & Merge

```{r, include = FALSE}
english_words <- read_csv('words_alpha.txt') %>% unlist()

custom_replace <- function(tweet){
  temp <- tweet %>% 
    iconv('UTF-8', 'UTF-8', sub = '') %>% 
    str_replace_all('[[:punct:]]', '') %>% 
    tolower() %>% str_split('\\s+') %>% 
    unlist()
  result <- temp[temp%in%english_words & !(temp%in%c(stopwords("english"), "rt"))] %>% 
    str_c(collapse=" ")
  
  if (length(result) == 0) {result <- c("")}
  return(result)
}

all_tweets[,1] <- all_tweets[,1] %>% 
  iconv('UTF-8', 'UTF-8', sub = '')

names(all_tweets) <- "Tweets"

all_tweets <- all_tweets %>% 
  ddply(.variables = "Tweets", .fun = function(i) custom_replace(i))

all_tweets <- all_tweets %>% select("V1") %>% filter(V1 != "")
```
Clean Up Text, Removing Stopwords and Invalid Strings

```{r}
all_corpus <- all_tweets %>% 
  VectorSource() %>% 
  Corpus()

# all_corpus <- all_corpus %>%
#   tm_map(content_transformer(tolower))  %>% 
#   tm_map(removePunctuation) %>% 
#   tm_map(stripWhitespace)  

all_dtm <- DocumentTermMatrix(all_corpus)
```
Get dtm (same way as CountingCockroaches)

```{r}
num_topics <- 2:10
num_terms <- 40
all_topics <- list()
all_terms <- list()
for ( k in num_topics ){
  all_topics[[k-1]] <- all_dtm %>% 
    LDA(method = "Gibbs", k = k, control = list(seed = 42))
  
  all_terms[[k-1]] <- all_topics[[k-1]] %>% 
    terms(k = num_terms) 
}
```
Fit LDA Model for different parameter values


```{r}
betas <- list()
for ( n in 1:length(all_topics) ) {
  betas[[n]] <- all_topics[[n]] %>% tidy(matrix = "beta")
}

top_terms <- list()
for (k in 1:length(betas)) {
  
  top_terms[[k]] <- betas[[k]] %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    arrange(topic, -beta)
  
}

for ( t in 1:length(top_terms) ) {
  print(  
    top_terms[[t]] %>%
      mutate(term = reorder(term, beta)) %>%
      ggplot(aes(term, beta, fill = factor(topic))) +
      geom_col(show.legend = FALSE) +
      facet_wrap( ~topic, scales = "free") +
      coord_flip()
  )
}
```
Visualize Results
